{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fine tuninig\n",
    "\n",
    "世の中にはたくさんの学習済みのモデルがあります。それらを使ってfine tuningを行います  \n",
    "今回はtensorflow_hubにある学習済みモデルを使います。\n",
    "\n",
    "### 学習済みモデルの再利用\n",
    "\n",
    "まずはモデルを読み込み、使用してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo pip install -q -U tf-hub-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4  \n",
    "今回はこのモデルを使用します。mobile_netは軽量で高速なモデルで、精度もそれなりに高く、非常に使いやすいモデルです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_url =\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\"\n",
    "\n",
    "IMAGE_SHAPE = (224, 224)\n",
    "\n",
    "classifier = tf.keras.Sequential([\n",
    "    hub.KerasLayer(classifier_url, input_shape=IMAGE_SHAPE+(3,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "\n",
    "image_url = \"https://dol.ismcdn.jp/mwimgs/7/1/670m/img_71c53c1d81500a1cf73a4f543e72413f27838.jpg\" # 自分で指定\n",
    "\n",
    "img = tf.keras.utils.get_file('inu.jpg', image_url)\n",
    "img = Image.open(img).resize(IMAGE_SHAPE)\n",
    "img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(img) / 255.0\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch_sizeの分だけ次元を増やしてあげてから、predictしてみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## <todo> predictを行ってみましょう\n",
    "img = ___ ## batch_size部分の次元を合わせます (1,  244, 244, 3)\n",
    "result = ___ ## predictを行います\n",
    "predicted_class = np.___(___, axis=-1) ## 一番確率の高い要素を出力します\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "予測結果が得られたので、このclass_idがなんに紐づいているのか定義から確認してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_path = tf.keras.utils.get_file('ImageNetLabels.txt','https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\n",
    "imagenet_labels = np.array(open(labels_path).read().splitlines())\n",
    "predicted_class_name = imagenet_labels[predicted_class]\n",
    "print(predicted_class_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "きちんと学習済みで推論できていることが確認できます。 \n",
    "他にも何枚か試してみてください。\n",
    "\n",
    "ロードしたモデルについても確認しておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainable params: 0 からこのモデルが再トレーニングできないモデルなことがわかります。\n",
    "\n",
    "## 最終層の再学習\n",
    "    \n",
    "tensorflow_hubには完全に使用可能なモデルから、最終層やいくつかの層をあえて取り外し、特徴ベクトルを取り出せるようなモデルもあります。  \n",
    "今回は再学習が目的なので、特徴量ベクトルだけ取り出し、最終層を再学習させます。\n",
    "\n",
    "そのため、再度、特徴量ベクトルが取り出すことができるモデルを読み込みます。  \n",
    "https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4  \n",
    "ここからurlをコピーして使います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector_url = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "\n",
    "IMAGE_SHAPE = (224, 224)\n",
    "NUM_CLASSES=2\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    hub.KerasLayer(feature_vector_url, input_shape=IMAGE_SHAPE+(3,)),\n",
    "    ## <todo> 最終層にunit数がNUM_CLASSES, activationがsoftmaxのDenseを追加してみましょう。\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最終層につけたDenseがTrainableで、特徴量ベクトルの層がUntrainableになっています。\n",
    "\n",
    "モデルの準備はできたので、学習データセットを用意します。\n",
    "\n",
    "https://www.tensorflow.org/datasets/catalog/overview  \n",
    "上記のカタログの中から、  \n",
    "https://www.tensorflow.org/datasets/catalog/horses_or_humans  \n",
    "こちらのデータセットを今回は使います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "TRAIN_DATA_URL=https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
    "VAL_DATA_URL=https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
    "curl -o train.zip ${TRAIN_DATA_URL}\n",
    "curl -o val.zip ${VAL_DATA_URL}\n",
    "rm -rf train\n",
    "rm -rf val\n",
    "mkdir -p train\n",
    "mkdir -p val\n",
    "unzip -qq train.zip -d train\n",
    "unzip -qq val.zip -d val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "\n",
    "train_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n",
    "train_image_data = train_image_generator.flow_from_directory(\"./train\", target_size=IMAGE_SHAPE)\n",
    "\n",
    "eval_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n",
    "eval_image_data = eval_image_generator.flow_from_directory(\"./val\", target_size=IMAGE_SHAPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "試しにclassifierで推論してみると、"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, label_batch in train_image_data:\n",
    "  print(\"Image batch shape: \", image_batch.shape)\n",
    "  print(\"Label batch shape: \", label_batch.shape)\n",
    "  result = classifier.predict(image_batch)\n",
    "  predicted_class = np.argmax(result[0], axis=-1)\n",
    "  print(imagenet_labels[predicted_class])\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "さてデータの準備ができたので、訓練を開始します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## <todo> optimizerがadam, lossがcategorical_crossentropyのモデルをコンパイルしてみましょう。\n",
    "model.___(\n",
    "  ___,\n",
    "  ___,\n",
    "  metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollectBatchStats(tf.keras.callbacks.Callback):\n",
    "  def __init__(self):\n",
    "    self.batch_losses = []\n",
    "    self.batch_acc = []\n",
    "\n",
    "  def on_train_batch_end(self, batch, logs=None):\n",
    "    self.batch_losses.append(logs['loss'])\n",
    "    self.batch_acc.append(logs['categorical_accuracy'])\n",
    "    self.model.reset_metrics()\n",
    "    \n",
    "steps_per_epoch = np.ceil(train_image_data.samples/train_image_data.batch_size)\n",
    "\n",
    "batch_stats_callback = CollectBatchStats()\n",
    "\n",
    "# <todo> 適切な引数を入れてmodelのtrainingをしましょう。\n",
    "history = model.fit_generator(generator=___, epochs=1,\n",
    "                              steps_per_epoch=___,\n",
    "                              validation_data=___,\n",
    "                              callbacks = [batch_stats_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可視化\n",
    "訓練が終わったら、lossとaccuracyの推移を確認してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,2])\n",
    "plt.plot(batch_stats_callback.batch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(batch_stats_callback.batch_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
