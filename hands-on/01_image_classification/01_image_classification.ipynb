{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion-MNIST を使ったClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fashion-MNIST データセットを使って画像をclassificationを行います"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset の確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回はオープンデータのfashion-MNISTを使うので、中身を確認します\n",
    "\n",
    "データの大元はここにあります。\n",
    "https://github.com/zalandoresearch/fashion-mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "(X_train_orig, y_train_orig), (X_test_orig, y_test_orig) = fashion_mnist.load_data()\n",
    "\n",
    "## <TODO> それぞれのデータ形を表示してみましょう\n",
    "print(\"train feature shape\", X_train_orig.___)\n",
    "print(\"train label shape\", y_train_orig.___)\n",
    "print(\"test feature shape\", X_test_orig.___)\n",
    "print(\"test label shape\", y_test_orig.___)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練データは60,000件、テストデータは10,000件で、画像のshapeは(28, 28)であることがわかります。縦横しかないからカラー情報しかもたないグレースケール画像であることがわかります。\n",
    "\n",
    "featureとなる画像データを見てみると様々なファッションアイテムの画像が入っています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def show(n_cols, n_rows, train_orig):\n",
    "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(16,4))\n",
    "    for ax, pixels in zip(axs.flat, train_orig):\n",
    "        ax.imshow(pixels, cmap=\"gray\")\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    plt.show()\n",
    "\n",
    "show(20, 5, X_train_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labelの意味は https://github.com/zalandoresearch/fashion-mnist#labels ここにあります。\n",
    "\n",
    "データのそれぞれのカテゴリごとに6,000件ずつ、均等にはいっているようです"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "labels = [\n",
    "    'T-shirt/top',\n",
    "    'Trouser',\n",
    "    'Pullover',\n",
    "    'Dress',\n",
    "    'Coat',\n",
    "    'Sandal',\n",
    "    'Shirt',\n",
    "    'Sneaker',\n",
    "    'Bag',\n",
    "    'Ankle boot',\n",
    "]\n",
    "left = range(0, 10)\n",
    "height = np.zeros(10)\n",
    "for v in y_train_orig:\n",
    "    height[v] += 1\n",
    "    \n",
    "plt.xticks(rotation=45)\n",
    "plt.bar(left, height, tick_label=labels, align=\"center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これでデータについてはわかったので、モデルを作成していきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルを作成するにあたって、データの前処理を行います。\n",
    "ここでは3つの処理を行っています。\n",
    "- kerasのcnnで使用するメソッドであるConv2Dは入力のshapeとして(batch_size, rows, cols, channels)を取るため、データをexpandします。\n",
    "- データの正規化を行います。 (値の範囲を[0-255]から[0-1]にします。)\n",
    "- ラベルをone hot表現に変換します。('Trouser'が正解の場合、[0,1,0,0,0,0,0,0,0,0]になります。)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## <TODO> shapeを(batch_size, rows, cols, channels)にexpandする。 (batch_sizeはtrainning時に指定するため、現時点では全データ数で良いです。)\n",
    "X_train = np.___(_, _)\n",
    "X_test = np.___(_, _)\n",
    "\n",
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "\n",
    "## <TODO> グレースケールの 0-255 の値を 正規化して 0-1 の浮動小数にする\n",
    "X_train = ___\n",
    "X_test = ___\n",
    "\n",
    "## <TODO> one hot vectorにする\n",
    "y_train = tf.keras.utils.___(y_train_orig, _)\n",
    "y_test = tf.keras.utils.___(y_test_orig, _)\n",
    "\n",
    "print(\"one hot label shape\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kerasでmodelを作成する場合には2つの方法があります。 Sequential API を使う方法と、Funcional API を使う方法です。\n",
    "\n",
    "Sequential APIはシンプルで単純な構造のmodelを作る際に便利で、Functional APIは複数の入力やアウトプットをもったり、内部で分岐処理があるような複雑なモデルを作成する際に向いています。\n",
    "今回はSequential APIを用いてmodelを作ってみましょう\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/layers ここからcnnを使ってmodelを組んでみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "\n",
    "def cnn():\n",
    "    ## <todo> 資料を参考にモデルを組んでみましょう。\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training: 訓練\n",
    "\n",
    "まずモデルを組み立てて、中身を見てみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%rm -rf ./logs\n",
    "\n",
    "model = cnn()\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\")\n",
    "\n",
    "## <todo> モデルをコンパイルする。\n",
    "model.___(___, ___, metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "## <todo> 学習を開始する。\n",
    "model.___(___, ___, ___, ___, ___, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## <todo> modelの全体像を確認する。\n",
    "model.___()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test: 検証\n",
    "\n",
    "訓練が終わったので、訓練データには存在しないデータで検証をしていきます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## <todo> modelの検証を行う。\n",
    "model.___(___, ___)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "表示されている情報は lossとcategorical_accuracyです。訓練の結果とどの程度違いがあったでしょうか？ overfitはしていないでしょうか？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensorboardでの可視化\n",
    "また、tensorboardを使うことによって訓練結果の可視化ができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ./logsをgcsに渡す\n",
    "\n",
    "USER = \"username\" # 自分の名前\n",
    "BUCKET = \"mixi-ml-handson-2021\"\n",
    "LOCAL_TRAIN_DIR = \"local_train\"\n",
    "\n",
    "!gsutil cp -r ./logs gs://{BUCKET}/{USER}/{LOCAL_TRAIN_DIR}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 出力結果をCloud Shellで実行\n",
    "print('tensorboard --logdir gs://{}/{}/{}/logs --port 8080'.format(BUCKET, USER, LOCAL_TRAIN_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記出力結果をCloud Shellで実行します。\n",
    "\n",
    "一度cloud consoleのダッシュボードに戻り、右上のアイコンの中の一つにある **Cloud Shellをアクティブにする** をクリックしてください。\n",
    "\n",
    "cloud Shellが立ち上がったら、出力結果を貼り付けて実行してみてください。\n",
    "\n",
    "終わったら、cloud shell内右上の歯車マークの右隣にある **ウェブでプレビュー**をクリックし**ポート8080でプレビュー**を選択してください。\n",
    "\n",
    "これで、学習推移がtensorboardで確認できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prediction: 推論\n",
    "\n",
    "では出来上がったmodelにリクエストを投げて実際に処理を行ってみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## <todo> modelから予測結果を受け取る。\n",
    "predictions = model.___(X_test[10:20])\n",
    "\n",
    "for i, p in enumerate(predictions):\n",
    "    print(i, labels[np.argmax(p)], \"{}%\".format(p[np.argmax(p)]*100))\n",
    "show(10, 1, X_test_orig[10:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存\n",
    "\n",
    "出来上がったモデルは現時点では、notebookのメモリ上にしかありません。これを保存します。  \n",
    "save_formatはtensorflow2.0以降のデフォルトの保存形式になっているsaved_model形式で保存を行うための指定です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER    = \"username\" ## 自分の名前\n",
    "BUCKET  = \"mixi-ml-handson-2021\"\n",
    "VERSION = \"001\"\n",
    "\n",
    "## <todo> modelを保存する。\n",
    "model.___(\"gs://{}/{}/{}\".format(BUCKET, USER, VERSION), save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 追加課題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ modelの構成を変更して、どのくらい性能が変わるか確認してみよう\n",
    "  + Dropoutの有無、正規化の有無、CNNからDNNにした場合\n",
    "+ 時間に余裕がある場合は 01ex_pruningに進もう"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}