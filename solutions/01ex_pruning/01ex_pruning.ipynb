{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "capital-finnish",
   "metadata": {},
   "source": [
    "# Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-electricity",
   "metadata": {},
   "source": [
    "このチャプターでは、modelのpruningを行っていきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "unusual-desire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "inclusive-latvia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import numpy as np\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-cookbook",
   "metadata": {},
   "source": [
    "### データセットの準備\n",
    "評価で使用するため、再度Fashion-MNISTデータセットをロードして、\n",
    "前処理も行なっておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dressed-university",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (60000, 28, 28, 1)\n",
      "X_test shape (10000, 28, 28, 1)\n",
      "one hot label shape (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "(X_train_orig, y_train_orig), (X_test_orig, y_test_orig) = fashion_mnist.load_data()\n",
    "\n",
    "## shapeを(batch_size, rows, cols, channels)にexpandする。 (batch_sizeはtrainning時に指定するため、現時点では全データ数で大丈夫です。)\n",
    "X_train = np.expand_dims(X_train_orig, -1)\n",
    "X_test = np.expand_dims(X_test_orig, -1)\n",
    "\n",
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "\n",
    "## グレースケールの 0-255 の値を 正規化して 0-1 の浮動小数にする\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "## one hot vectorにする\n",
    "y_train = tf.keras.utils.to_categorical(y_train_orig, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test_orig, 10)\n",
    "\n",
    "print(\"one hot label shape\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developed-variation",
   "metadata": {},
   "source": [
    "### モデルのロード\n",
    "01で保存したFashion-MNISTモデルをロードします"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "essential-lodging",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "USER    = \"username\" # 自分の名前\n",
    "BUCKET  = \"mixi-ml-handson-2020\"\n",
    "VERSION = \"001\"\n",
    "\"\"\"\n",
    "\n",
    "base_model = tf.keras.models.load_model(\"gs://{}/{}/{}\".format(BUCKET, USER, VERSION))\n",
    "\n",
    "# ベースモデルを一時保存しておく\n",
    "_, base_model_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(base_model, base_model_file, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-pastor",
   "metadata": {},
   "source": [
    "### ベースモデルの精度確認\n",
    "再度、ベースモデルの評価を確認してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "matched-rolling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 4ms/step - loss: 0.2356 - categorical_accuracy: 0.9232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2356211245059967, 0.9232000112533569]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.evaluate(X_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-andrew",
   "metadata": {},
   "source": [
    "### 重みの確認\n",
    "\n",
    "pruningとは、重みが小さいエッジを取り去って、パラメータを削減する手法になります。  \n",
    "パラメータが少なくなれば、その分モデルのサイズは小さくなり、高速化されます。  \n",
    "しかし、今回のモデルの重みに削減する余地はあるでしょうか。\n",
    "\n",
    "実際に重みの値を確認してみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loose-license",
   "metadata": {},
   "source": [
    "まず、再度モデルの構成を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "endless-ultimate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, None, None, 32)    320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, None, None, 64)    18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, None)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               819328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 876,362\n",
      "Trainable params: 876,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-belly",
   "metadata": {},
   "source": [
    "この中のうち、`conv2d`の3つと`dense`の2つが層を構成しています。  \n",
    "これらの層の重みからヒストグラムを作成してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "female-flood",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_weights_histgram(model, layers_index):\n",
    "    weight_list = model.layers[layers_index].weights[0].numpy().flatten()\n",
    "    plt.hist(weight_list, bins=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "christian-savage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# conv2dまたはdense層のindexを入れて、それぞれの重みをplotしてみましょう\n",
    "draw_weights_histgram(base_model, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-village",
   "metadata": {},
   "source": [
    "だいたいどの層をplotしてみても、0.0付近に値が集中していたのではないでしょうか。  \n",
    "0.0付近のweightは、消去しても精度に大きな影響を与えないはずなので、このモデルにはpruningする余地が十分あるといえそうです。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-intent",
   "metadata": {},
   "source": [
    "### pruningモデルを定義\n",
    "公式の[Pruning in Keras example](https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras)を参考にpruningモデルを定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "similar-italy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "def compute_necessary_steps(batch_size, epochs):\n",
    "    return np.ceil(X_train.shape[0] / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "end_step = compute_necessary_steps(batch_size=32, epochs=5)\n",
    "\n",
    "# 最初に10%をpruning、最終的には70%をpruningする様にスケジューリング\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.10,\n",
    "                                                               final_sparsity=0.70,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(base_model, **pruning_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "clear-consumer",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_pruning.compile(\n",
    "    optimizer='adam',\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    metrics=[tf.keras.metrics.CategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-opposition",
   "metadata": {},
   "source": [
    "### 学習\n",
    "pruningモデルが定義できたので、再学習させます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "vital-example",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "   6/1688 [..............................] - ETA: 2:42 - loss: 0.1235 - categorical_accuracy: 0.9409WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0113s vs `on_train_batch_begin` time: 0.0277s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0113s vs `on_train_batch_end` time: 0.0444s). Check your callbacks.\n",
      "1688/1688 [==============================] - 35s 19ms/step - loss: 0.1413 - categorical_accuracy: 0.9466 - val_loss: 0.2071 - val_categorical_accuracy: 0.9322\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 31s 18ms/step - loss: 0.1427 - categorical_accuracy: 0.9483 - val_loss: 0.2045 - val_categorical_accuracy: 0.9297\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 31s 18ms/step - loss: 0.1476 - categorical_accuracy: 0.9442 - val_loss: 0.2099 - val_categorical_accuracy: 0.9283\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 31s 18ms/step - loss: 0.1578 - categorical_accuracy: 0.9415 - val_loss: 0.2084 - val_categorical_accuracy: 0.9300\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 31s 18ms/step - loss: 0.1476 - categorical_accuracy: 0.9448 - val_loss: 0.2109 - val_categorical_accuracy: 0.9277\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f688ebfcf50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%rm -rf ./pruning_logs\n",
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir='pruning_logs'),\n",
    "]\n",
    "model_for_pruning.fit(X_train, y_train, batch_size=32, epochs=5, validation_split=0.1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-swiss",
   "metadata": {},
   "source": [
    "### 評価\n",
    "学習が終わったら、これまでと同じように評価してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "killing-cassette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2239 - categorical_accuracy: 0.9242\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.22388991713523865, 0.9241999983787537]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_for_pruning.evaluate(X_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-oasis",
   "metadata": {},
   "source": [
    "モデルの精度はベースモデルと比較してどうなっているでしょうか。  \n",
    "ほとんど変わってなければ、精度に影響を与えずにpruningされていることになります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-signal",
   "metadata": {},
   "source": [
    "### 可視化\n",
    "01と同じように、学習結果をtensorboardで可視化してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "opposite-security",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./pruning_logs/train/events.out.tfevents.1619495867.rio-tensorflow-24.profile-empty [Content-Type=application/octet-stream]...\n",
      "Copying file://./pruning_logs/train/events.out.tfevents.1619495864.rio-tensorflow-24.14246.2561.v2 [Content-Type=application/octet-stream]...\n",
      "Copying file://./pruning_logs/train/plugins/profile/2021_04_27_03_57_47/rio-tensorflow-24.xplane.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://./pruning_logs/train/plugins/profile/2021_04_27_03_57_47/rio-tensorflow-24.input_pipeline.pb [Content-Type=application/octet-stream]...\n",
      "- [4 files][642.1 KiB/642.1 KiB]                                                \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying file://./pruning_logs/train/plugins/profile/2021_04_27_03_57_47/rio-tensorflow-24.kernel_stats.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://./pruning_logs/train/plugins/profile/2021_04_27_03_57_47/rio-tensorflow-24.overview_page.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://./pruning_logs/train/plugins/profile/2021_04_27_03_57_47/rio-tensorflow-24.memory_profile.json.gz [Content-Type=application/json]...\n",
      "Copying file://./pruning_logs/train/plugins/profile/2021_04_27_03_57_47/rio-tensorflow-24.trace.json.gz [Content-Type=application/json]...\n",
      "Copying file://./pruning_logs/train/plugins/profile/2021_04_27_03_57_47/rio-tensorflow-24.tensorflow_stats.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://./pruning_logs/validation/events.out.tfevents.1619495897.rio-tensorflow-24.14246.24217.v2 [Content-Type=application/octet-stream]...\n",
      "Copying file://./pruning_logs/metrics/events.out.tfevents.1619495864.rio-tensorflow-24.14246.2498.v2 [Content-Type=application/octet-stream]...\n",
      "| [11 files][896.8 KiB/896.8 KiB]                                               \n",
      "Operation completed over 11 objects/896.8 KiB.                                   \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "USER = \"username\" # 自分の名前\n",
    "BUCKET = \"mixi-ml-handson-2020\"\n",
    "LOCAL_TRAIN_DIR = \"pruning_train\"\n",
    "'''\n",
    "USER = \"rio\"\n",
    "BUCKET = \"rio_ml\"\n",
    "LOCAL_TRAIN_DIR = \"pruning_train\"\n",
    "\n",
    "!gsutil cp -r ./pruning_logs gs://{BUCKET}/{USER}/{LOCAL_TRAIN_DIR}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "russian-programming",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard --logdir gs://rio_ml/rio/pruning_train/pruning_logs --port 8080\n"
     ]
    }
   ],
   "source": [
    "## 出力結果をCloud Shellで実行\n",
    "print('tensorboard --logdir gs://{}/{}/{}/pruning_logs --port 8080'.format(BUCKET, USER, LOCAL_TRAIN_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-mountain",
   "metadata": {},
   "source": [
    "学習の推移やshcedule通りにpruningされていったかなどを確認してみてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-patch",
   "metadata": {},
   "source": [
    "### pruningモデルを圧縮\n",
    "pruningすることが出来たので、モデルの圧縮を行いましょう。\n",
    "\n",
    "[公式](https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras#create_3x_smaller_models_from_pruning)によると、圧縮を確認するには`tfmot.sparsity.keras.strip_pruning`と標準の圧縮アルゴリズムの適用（gzipなど）の両方が必要とのことなので、\n",
    "その対応をしていきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "random-defeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "\n",
    "# pruningしたモデルを一時保存\n",
    "_, pruned_model_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model_for_export, pruned_model_file, include_optimizer=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "editorial-oasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gzipを適応した後のsizeをkbで返す関数\n",
    "def get_gzipped_model_size_kb(file):\n",
    "    # Returns size of gzipped model, in bytes.\n",
    "    _, zipped_file = tempfile.mkstemp('.zip')\n",
    "    with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "        f.write(file)\n",
    "    return int(os.path.getsize(zipped_file) / 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-advisory",
   "metadata": {},
   "source": [
    "準備ができたので、各モデルにおける圧縮の効果を確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adult-sociology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model size    : 3199 kb\n",
      "pruned model size : 1338 kb\n"
     ]
    }
   ],
   "source": [
    "print(\"base model size    : {} kb\".format(get_gzipped_model_size_kb(base_model_file)))\n",
    "print(\"pruned model size : {} kb\".format(get_gzipped_model_size_kb(pruned_model_file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-gender",
   "metadata": {},
   "source": [
    "モデルが1/3ほどに圧縮されたことが確認できているでしょうか。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-monaco",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
